{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN9za71s+AQUhoNjDpHyp+O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizjwh/groupIAI_5take2/blob/main/5%20Completely%20New%20Model/Testing_Lizzys_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-RHzQW_fIQJ"
      },
      "outputs": [],
      "source": [
        "#install torchvision and kaggle\n",
        "!pip install torchvision\n",
        "!pip install kaggle\n",
        "!pip install tqdm\n",
        "!pip install colorama"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import  needed libraries and check the used gpu\n",
        "import torch\n",
        "from torch import nn, optim, tensor\n",
        "from torchvision import transforms, models ,datasets\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import auc"
      ],
      "metadata": {
        "id": "KvuVfCJRfsRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check whether we have a GPU.  Use it if we do.\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "rEfBZiALgtgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! export KAGGLE_USERNAME=\"emmet454\" && export KAGGLE_KEY=\"ee00fbc0728a71f5c5f712029e3ef004\" && kaggle datasets download --force --unzip emilyburt/intro-to-ai"
      ],
      "metadata": {
        "id": "ZAnYx9ebftQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimplifiedModel(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(SimplifiedModel, self).__init__()\n",
        "\n",
        "        # Load a pretrained DenseNet model\n",
        "        densenet_model = models.densenet121(pretrained=True)\n",
        "\n",
        "        # Use only the feature extractor part of DenseNet\n",
        "        self.features = densenet_model.features\n",
        "\n",
        "        # Modify the classifier part\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Flatten(),\n",
        "            nn.Dropout(p=0.3), #next test for this\n",
        "            nn.Linear(1024, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of the SimplifiedModel\n",
        "model = SimplifiedModel(in_channels=3,num_classes=27).to(device)"
      ],
      "metadata": {
        "id": "UWGrpZDifu_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lizjwh/groupIAI_5take2\n",
        "model.load_state_dict(torch.load('groupIAI_5take2/5 Completely New Model/Pretrained Densenet, 11 epochs with dropout.pth'))\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "fTFAXDNNgLBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#These functions allow each folder to be combined\n",
        "from torch.utils.data import ConcatDataset\n",
        "\n",
        "def create_dataset(root_dir):\n",
        "    \"\"\"\n",
        "    Creates an ImageFolder dataset from the specified root directory.\n",
        "    \"\"\"\n",
        "    data_transforms = transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                               [0.229, 0.224, 0.225])])\n",
        "    dataset = datasets.ImageFolder(root_dir, transform=data_transforms)\n",
        "    return dataset\n",
        "\n",
        "def combine_datasets(root_folders):\n",
        "    \"\"\"\n",
        "    Combines datasets from multiple root folders into one dataset.\n",
        "    \"\"\"\n",
        "    datasets = [create_dataset(folder) for folder in root_folders]\n",
        "    combined_dataset = ConcatDataset(datasets)\n",
        "\n",
        "    # Extract class-to-index mappings from individual datasets and merge them\n",
        "    class_to_idx = {}\n",
        "    for dataset in datasets:\n",
        "        class_to_idx.update(dataset.class_to_idx)\n",
        "\n",
        "    return combined_dataset, class_to_idx\n",
        "\n",
        "def main():\n",
        "  #choose which folders to include in test here\n",
        "    root_folders = ['/content/Dataset/Restricted mobility/Left hand',\n",
        "                    '/content/Dataset/Restricted mobility/Right hand',\n",
        "                    '/content/Dataset/Full Mobility/Left hand',\n",
        "                    '/content/Dataset/Full Mobility/Right hand']\n",
        "\n",
        "    combined_dataset, combined_dataset.class_to_idx = combine_datasets(root_folders)\n",
        "\n",
        "    print(f\"Class to index mapping: {combined_dataset.class_to_idx}\")\n",
        "    return combined_dataset\n",
        "\n",
        "combined_dataset = main()\n",
        "\n",
        "\n",
        "#define the transform for the dataset\n",
        "#test_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
        "#                                      transforms.ToTensor(),\n",
        "#                                     transforms.Normalize([0.485, 0.456, 0.406],\n",
        " #                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "#transform the data\n",
        "#test_data = datasets.ImageFolder(path,test_transforms)\n",
        "#path = '/content/Dataset/Restricted mobility/Right hand'\n",
        "#test_data.append(datasets.ImageFolder(path,test_transforms))\n",
        "#path = '/content/Dataset/Full Mobility/Left hand'\n",
        "#test_data.append(datasets.ImageFolder(path,test_transforms))\n",
        "#path = '/content/Dataset/Full Mobility/Right hand'\n",
        "#test_data.append(datasets.ImageFolder(path,test_transforms))\n",
        "#print(f\"class to index mapping: {test_data.class_to_idx}\")\n",
        "\n",
        "#load some of the test data\n",
        "testloader = torch.utils.data.DataLoader(combined_dataset, batch_size=50, shuffle=True)\n",
        "images, labels = next(iter(testloader))\n",
        "print(labels)\n",
        "#print(images.size())"
      ],
      "metadata": {
        "id": "TMBQPTBGgKUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Confusion matrix"
      ],
      "metadata": {
        "id": "VLRTuNe3goYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batchsize = 20\n",
        "test_loader = torch.utils.data.DataLoader(dataset=combined_dataset,\n",
        "                                          batch_size=batchsize,\n",
        "                                          shuffle=True)\n",
        "\n",
        "def test(classes):\n",
        "    pred = []\n",
        "    true = []\n",
        "\n",
        "    # Iterate through all batches in the test_loader\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass through the model\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # Convert predicted and true labels to class names\n",
        "    try: #Lizzy unindented the following because it wasn't working\n",
        "        pred.extend([classes[label.item()] for label in predicted])\n",
        "        true.extend([classes[label.item()] for label in labels])\n",
        "    except KeyError as e:\n",
        "        print(f\"Error: {e} not found in classes dictionary.\")\n",
        "        print(f\"Problematic labels: {predicted}, {labels}\")\n",
        "\n",
        "    return pred, true\n",
        "\n",
        "\n",
        "#invert class_to_idx keys to values and vice versa.\n",
        "classes = combined_dataset.class_to_idx\n",
        "classes = {value: key for key, value in classes.items()}\n",
        "\n",
        "pred, true = test(classes)\n",
        "print(pred, true)"
      ],
      "metadata": {
        "id": "395s0YXGgiKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotConfusionMatrix(pred, true, classes):\n",
        "    # Change classes dictionary to this format {'A': 'A', 'B': 'B', 'C': 'C'...} for labelling the axis later\n",
        "    classes = {value: value for key, value in classes.items()}\n",
        "\n",
        "    # Convert class_to_idx dictionary to list of class names\n",
        "    unique_classes = sorted(set(true + pred))\n",
        "\n",
        "    # Ensure that all classes are included, even if they are not present in the batch of data\n",
        "    all_classes = sorted(set(classes.values()))\n",
        "\n",
        "    # Create confusion matrix\n",
        "    cf_matrix = confusion_matrix(\n",
        "        [classes[label] for label in true],\n",
        "        [classes[label] for label in pred],\n",
        "        labels=all_classes\n",
        "    )\n",
        "\n",
        "    # Create DataFrame using class names for index and columns\n",
        "    df_cm = pd.DataFrame(cf_matrix, index=all_classes, columns=all_classes)\n",
        "\n",
        "    # Normalize the confusion matrix by row (i.e., by the number of true instances for each class)\n",
        "    df_cm = df_cm.div(df_cm.sum(axis=1), axis=0)\n",
        "\n",
        "    # Add 0s to empty cells\n",
        "    df_cm = df_cm.fillna(0.00)\n",
        "    #print(df_cm)\n",
        "\n",
        "    plt.figure(figsize=(12, 7))\n",
        "    print(classes)\n",
        "    sn.heatmap(df_cm, annot=True, fmt=\".2f\")  # Adjust fmt as needed for displaying float values\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title('Normalized Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# #To run this cell independently you need these lines and some sample predictions\n",
        "# classes = combined_dataset.class_to_idx\n",
        "# classes = {value: key for key, value in classes.items()}\n",
        "# pred = ['C','D','F','G','W','L','P']\n",
        "# true = ['C','L','X','G','W','L','P']\n",
        "\n",
        "# Call the function to plot the confusion matrix\n",
        "plotConfusionMatrix(pred, true, classes)"
      ],
      "metadata": {
        "id": "H1xr245hg1gh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}