{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNt99N/KfYAlXwxJ2FKYS1q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lizjwh/groupIAI_5take2/blob/main/5%20Completely%20New%20Model/CommpletelyNewModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNDCl6vme0RF",
        "outputId": "2e7fe9f7-3b6a-4664-9132-137cad181a01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.1.0+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchvision) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "#install torchvision and kaggle\n",
        "!pip install torchvision\n",
        "!pip install kaggle\n",
        "!pip install tqdm\n",
        "!pip install colorama"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import  needed libraries and check the used gpu\n",
        "import torch\n",
        "from torch import nn,optim\n",
        "from torchvision import transforms, models ,datasets\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid"
      ],
      "metadata": {
        "id": "UxU7_dxbgvN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! export KAGGLE_USERNAME=\"emmet454\" && export KAGGLE_KEY=\"ee00fbc0728a71f5c5f712029e3ef004\" && kaggle datasets download --force --unzip emilyburt/intro-to-ai"
      ],
      "metadata": {
        "id": "HOAmwGpFgryu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lines to reorganise the folder system\n",
        "def rename_folder(folder_path, new_name):\n",
        "    \"\"\"\n",
        "    Rename a folder.\n",
        "\n",
        "    Args:\n",
        "    - folder_path (str): Path to the folder to be renamed.\n",
        "    - new_name (str): New name for the folder.\n",
        "    \"\"\"\n",
        "    # Check if the folder exists\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Error: Folder '{folder_path}' does not exist.\")\n",
        "        return\n",
        "\n",
        "    # Extract the directory path and folder name\n",
        "    directory, old_name = os.path.split(folder_path)\n",
        "\n",
        "    # Create the new path with the new folder name\n",
        "    new_path = os.path.join(directory, new_name)\n",
        "\n",
        "    try:\n",
        "        # Rename the folder\n",
        "        os.rename(folder_path, new_path)\n",
        "        print(f\"Folder '{folder_path}' renamed to '{new_path}'.\")\n",
        "    except OSError as e:\n",
        "        print(f\"Error: Failed to rename folder '{folder_path}' to '{new_path}': {e}\")\n",
        "\n",
        "\n",
        "folder_path = \"/content/Dataset/Full Mobility/Left hand/Space\"\n",
        "new_name = \"space\"\n",
        "rename_folder(folder_path, new_name)\n",
        "\n",
        "folder_path = \"/content/Dataset/Full Mobility/Right hand/Space\"\n",
        "rename_folder(folder_path, new_name)\n",
        "\n",
        "folder_path = \"/content/Dataset/Restricted mobility/Left hand/Space\"\n",
        "rename_folder(folder_path, new_name)\n",
        "\n",
        "folder_path = \"/content/Dataset/Restricted mobility/Right hand/Space\"\n",
        "rename_folder(folder_path, new_name)\n",
        "\n",
        "\n",
        "#These functions allow each folder to be combined\n",
        "from torch.utils.data import ConcatDataset\n",
        "\n",
        "def create_dataset(root_dir):\n",
        "    \"\"\"\n",
        "    Creates an ImageFolder dataset from the specified root directory.\n",
        "    \"\"\"\n",
        "    data_transforms = transforms.Compose([transforms.Resize((224, 224)),\n",
        "                                          transforms.ToTensor(),\n",
        "                                          transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                               [0.229, 0.224, 0.225])])\n",
        "    dataset = datasets.ImageFolder(root_dir, transform=data_transforms)\n",
        "    return dataset\n",
        "\n",
        "def combine_datasets(root_folders):\n",
        "    \"\"\"\n",
        "    Combines datasets from multiple root folders into one dataset.\n",
        "    \"\"\"\n",
        "    datasets = [create_dataset(folder) for folder in root_folders]\n",
        "    combined_dataset = ConcatDataset(datasets)\n",
        "\n",
        "    # Define the desired order of classes\n",
        "    class_order = ['A', 'B', 'C', 'D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','Space']   # Define your desired order\n",
        "    # Extract class-to-index mappings from individual datasets and merge them\n",
        "    class_to_idx = {}\n",
        "    idx = -78\n",
        "    for dataset in datasets:\n",
        "        for class_name in class_order:\n",
        "            if class_name in dataset.class_to_idx:\n",
        "              if class_name == 'space':\n",
        "                class_to_idx[class_name] = 28\n",
        "                idx += 1\n",
        "              else:\n",
        "                class_to_idx[class_name] = idx\n",
        "                idx += 1\n",
        "\n",
        "    return combined_dataset, class_to_idx\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Choose which folders to include in test here\n",
        "    root_folders = ['/content/Dataset/Restricted mobility/Left hand',\n",
        "                    '/content/Dataset/Restricted mobility/Right hand',\n",
        "                    '/content/Dataset/Full Mobility/Left hand',\n",
        "                    '/content/Dataset/Full Mobility/Right hand']\n",
        "\n",
        "    combined_dataset, combined_class_to_idx = combine_datasets(root_folders)\n",
        "\n",
        "    print(f\"Class to index mapping: {combined_class_to_idx}\")\n",
        "    return combined_dataset, combined_class_to_idx\n",
        "\n",
        "combined_dataset, combined_dataset.class_to_idx = main()\n",
        "\n",
        "\n",
        "\n",
        "#define the transform for the dataset\n",
        "#test_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
        "#                                      transforms.ToTensor(),\n",
        "#                                     transforms.Normalize([0.485, 0.456, 0.406],\n",
        " #                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "#transform the data\n",
        "#test_data = datasets.ImageFolder(path,test_transforms)\n",
        "#path = '/content/Dataset/Restricted mobility/Right hand'\n",
        "#test_data.append(datasets.ImageFolder(path,test_transforms))\n",
        "#path = '/content/Dataset/Full Mobility/Left hand'\n",
        "#test_data.append(datasets.ImageFolder(path,test_transforms))\n",
        "#path = '/content/Dataset/Full Mobility/Right hand'\n",
        "#test_data.append(datasets.ImageFolder(path,test_transforms))\n",
        "#print(f\"class to index mapping: {test_data.class_to_idx}\")\n",
        "\n",
        "#load some of the test data\n",
        "testloader = torch.utils.data.DataLoader(combined_dataset, batch_size=50, shuffle=True)\n",
        "images, labels = next(iter(testloader))\n",
        "print(labels)\n",
        "#print(images.size())"
      ],
      "metadata": {
        "id": "RACnMA1Kgwzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transforms for the training data and testing data\n",
        "train_path='asl_alphabet_train'\n",
        "valid_path='asl_alphabet_valid'\n",
        "\n",
        "train_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
        "                                       transforms.RandomRotation(30),\n",
        "                                       transforms.RandomHorizontalFlip(p=0.3),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([transforms.Resize((224,224)),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])"
      ],
      "metadata": {
        "id": "RnW8rSE4hDuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data to loaders\n",
        "train_data = datasets.ImageFolder(train_path, transform=train_transforms)\n",
        "test_data = datasets.ImageFolder(valid_path, transform=test_transforms)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_data, batch_size=512, shuffle=True)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=512)\n",
        "\n",
        "#print used Device\n",
        "print(f\"Device used: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "#print class to index mapping\n",
        "print(f\"class to index mapping: {train_data.class_to_idx}\")"
      ],
      "metadata": {
        "id": "uLhr96RChrL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Now we can create our new model with Squeezenet1_1"
      ],
      "metadata": {
        "id": "oC9N8KNDhxbB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.squeezenet1_1(pretrained=True)"
      ],
      "metadata": {
        "id": "GNgzBZ41h4di"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}